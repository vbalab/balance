{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "388cfb98-baeb-4d43-b835-39f5bf4dbf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "horizon = 6\n",
    "train_end = datetime(year=2023, month=5, day=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56de0215-f0a3-401c-8f96-0f2db3dc0d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Data to be written\n",
    "scenario_data = {\n",
    "    #start_date\n",
    "     'Start_date':              str(train_end),\n",
    "    # ССВ\n",
    "     'SSV':                  [0.2 for h in range(horizon)],\n",
    "    # ФОР\n",
    "     'FOR':                  [0.2 for h in range(horizon)],\n",
    "    # Трансфертные ставки\n",
    "     'VTB_ftp_rate_[90d]':   [5 for h in range(horizon)],\n",
    "     'VTB_ftp_rate_[180d]':  [5.2 for h in range(horizon)],\n",
    "     'VTB_ftp_rate_[365d]':  [5.7 for h in range(horizon)],\n",
    "     'VTB_ftp_rate_[548d]':  [5 for h in range(horizon)],\n",
    "     'VTB_ftp_rate_[730d]':  [5.2 for h in range(horizon)],\n",
    "     'VTB_ftp_rate_[1095d]': [5.4 for h in range(horizon)],\n",
    "    \n",
    "    # Маржа бизнеса по срочностям\n",
    "     'margin_[90d]':         [0.7 for h in range(horizon)],\n",
    "     'margin_[180d]':        [0.7 for h in range(horizon)],\n",
    "     'margin_[365d]':        [0.7 for h in range(horizon)],\n",
    "     'margin_[548d]':        [0.7 for h in range(horizon)],\n",
    "     'margin_[730d]':        [0.7 for h in range(horizon)],\n",
    "     'margin_[1095d]':       [0.7 for h in range(horizon)],\n",
    "    \n",
    "    # Спред Привилегия - Массовый (на сколько в среднем ставки по сегменту Привилегия больше чем ставки по массовому сегменту)\n",
    "     'priv_spread':          [0.5 for h in range(horizon)],\n",
    "    # Спред ВИП - Массовый (на сколько в среднем ставки по сегменту ВИП больше чем ставки по массовому сегменту)\n",
    "     'vip_spread':           [0.8 for h in range(horizon)],\n",
    "    \n",
    "    # Ниже три спреда по разным типам опциональности по отношению к безопциональным вкладам (Подразумевается, что они, как правило, отрицательные)\n",
    "    # r - возможности пополнения, s - возможность расходных операций\n",
    "    \n",
    "    # На сколько ставка по расходным вкладам выше чем ставка по безопциональным вкладам (Если ниже - то со знаком минус)\n",
    "     'r0s1_spread':          [-0.2 for h in range(horizon)],\n",
    "    \n",
    "    # На сколько ставка по пополняемым вкладам выше чем ставка по безопциональным вкладам (Если ниже - то со знаком минус)\n",
    "     'r1s0_spread':          [-0.2 for h in range(horizon)],\n",
    "    \n",
    "    # На сколько ставка по расходно-пополняемым вкладам выше чем ставка по безопциональным вкладам (Если ниже - то со знаком минус)\n",
    "     'r1s1_spread':          [-0.2 for h in range(horizon)],\n",
    "    \n",
    "    # Ставка по лучшему предложению сбера\n",
    "     'SBER_max_rate':        [5.5 for h in range(horizon)],\n",
    "    \n",
    "    # Базовая ставка по НС\n",
    "     'SA_rate':              [5 for h in range(horizon)]\n",
    "}\n",
    " \n",
    "\n",
    "scenario_df_user = pd.DataFrame(scenario_data)\n",
    "# Serializing json\n",
    "json_object = json.dumps(scenario_data, indent=4)\n",
    " \n",
    "# Writing to sample.json\n",
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a25b1d2-0e0e-4bcd-b45c-2bd1c1a9aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "583dc85f-ffa9-4945-aa03-7e48cf47df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"dynbalance/examples/agg_res.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df979ab5-8a6f-48dc-b020-352541309878",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_balance_agg_report_dt']=df['balance']-df['balance_gain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba9b9d80-9035-477e-871c-69fd4bac9ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CA=pd.read_excel(\"dynbalance/examples/agg_res.xlsx\",sheet_name=\"CurrentAccounts\")\n",
    "df_SA=pd.read_excel(\"dynbalance/examples/agg_res.xlsx\",sheet_name=\"SavingAccounts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e4430ef-9868-4163-9a24-ad90d687e0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CA['segment']='mass'\n",
    "df1=df_CA.copy()\n",
    "df1['segment']='vip'\n",
    "df_CA=pd.concat([df_CA,df1])\n",
    "df1['segment']='priv'\n",
    "df_CA=pd.concat([df_CA,df1])\n",
    "df_CA.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7eb568c-a39d-45f7-acc8-889970b247b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict={}\n",
    "for report_dt in df['report_dt'].unique():\n",
    "    segment_dict={}\n",
    "    for segment in  df['segment'].unique():\n",
    "        results_dict[str(report_dt)[0:10]]=[]\n",
    "        dep_dict=[]\n",
    "        sa_dict={}\n",
    "        ca_dict={}\n",
    "        sub_df=df[(df['report_dt']==report_dt)&(df['segment']==segment)]\n",
    "        sub_df_SA=df_SA[(df_SA['report_dt']==report_dt)&(df_SA['segment']==segment)]\n",
    "        sub_df_CA=df_CA[(df_CA['report_dt']==report_dt)&(df_CA['segment']==segment)]\n",
    "        for i in range(len(sub_df)):\n",
    "            dep_dict.append({'replenishable_flg': str(df['replenishable_flg'][i]),\n",
    "                                        'subtraction_flg': str(df['subtraction_flg'][i]),\n",
    "                                        'target_maturity_days': str(df['target_maturity_days'][i]),\n",
    "                                        'start_balance': str(df['start_balance_agg_report_dt'][i]),\n",
    "                                        'balance_gain': str(df['balance_gain'][i]),\n",
    "                                        'balance': str(df['balance'][i]),\n",
    "                                        'newbusiness': str(df['newbusiness'][i]),\n",
    "                                        'contract_close': str(df['contract_close'][i]),\n",
    "                                        'early_withdrawal': str(df['early_withdrawal'][i]),\n",
    "                                        'operations': str(df['operations'][i]),\n",
    "                                        'interests'\t: str(df['interests'][i]),\n",
    "                                        'renewal'\t: str(df['renewal'][i])\n",
    "                \n",
    "            })\n",
    "        sa_dict.update({\"general\":float(sub_df_SA[['general']].values),\n",
    "                        \"kopilka\":float(sub_df_SA[['kopilka']].values),\n",
    "                        \"safe\":float(sub_df_SA[['safe']].values)\n",
    "                       })\n",
    "        ca_dict.update({\"current_accounts_balance_rur\":float(sub_df_CA[['current_accounts_balance_rur']].values) })\n",
    "        inter_dict={\"Deposits\":dep_dict}\n",
    "        inter_dict.update({\"SavingAccounts\":sa_dict})\n",
    "        inter_dict.update({\"CurrentAccounts\":ca_dict})\n",
    "        segment_dict.update({segment:inter_dict})\n",
    "        \n",
    "    results_dict.update({str(report_dt)[0:10]:segment_dict})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dfbbc806-5ce4-4b14-8517-e63c6f9ea06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/29 20:02:04 WARN security.UserGroupInformation: Exception encountered while running the renewal command for vtb70174694@REGION.VTB.RU. (TGT end time:1688065324000, renewalFailures: 0, renewalFailuresTotal: 1)\n",
      "ExitCodeException exitCode=1: kinit: Bad format in credentials cache (filename: /home/vtb70174694/.krb5cc_1000650088) while storing credentials\n",
      "\n",
      "\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)\n",
      "\tat org.apache.hadoop.util.Shell.run(Shell.java:902)\n",
      "\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)\n",
      "\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)\n",
      "\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation$TicketCacheRenewalRunnable.relogin(UserGroupInformation.java:1077)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation$AutoRenewalForUserCredsRunnable.run(UserGroupInformation.java:988)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "23/06/30 04:23:30 ERROR cluster.YarnClientSchedulerBackend: YARN application has exited unexpectedly with state SUCCEEDED! Check the YARN application logs for more details.\n",
      "23/06/30 04:25:31 ERROR util.Utils: Uncaught exception in thread YARN application state monitor\n",
      "org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [120 seconds]. This timeout is controlled by spark.rpc.askTimeout\n",
      "\tat org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)\n",
      "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.requestTotalExecutors(CoarseGrainedSchedulerBackend.scala:594)\n",
      "\tat org.apache.spark.scheduler.cluster.YarnSchedulerBackend.stop(YarnSchedulerBackend.scala:98)\n",
      "\tat org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.stop(YarnClientSchedulerBackend.scala:165)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:653)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2079)\n",
      "\tat org.apache.spark.SparkContext$$anonfun$stop$7.apply$mcV$sp(SparkContext.scala:1963)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1388)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:1962)\n",
      "\tat org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend$MonitorThread.run(YarnClientSchedulerBackend.scala:122)\n",
      "Caused by: java.util.concurrent.TimeoutException: Futures timed out after [120 seconds]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:223)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:227)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:220)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\t... 9 more\n",
      "23/06/30 04:25:31 ERROR cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(0,0,Map(),Set()) to AM was unsuccessful\n",
      "org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from null in 120 seconds. This timeout is controlled by spark.rpc.askTimeout\n",
      "\tat org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)\n",
      "\tat scala.util.Failure$$anonfun$recover$1.apply(Try.scala:216)\n",
      "\tat scala.util.Try$.apply(Try.scala:192)\n",
      "\tat scala.util.Failure.recover(Try.scala:216)\n",
      "\tat scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)\n",
      "\tat scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:36)\n",
      "\tat org.spark_project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:44)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:252)\n",
      "\tat scala.concurrent.Promise$class.complete(Promise.scala:55)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:157)\n",
      "\tat scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)\n",
      "\tat scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:36)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.processBatch$1(BatchingExecutor.scala:63)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:78)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:54)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:601)\n",
      "\tat scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:106)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:599)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:44)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:252)\n",
      "\tat scala.concurrent.Promise$class.tryFailure(Promise.scala:112)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:157)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:206)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:243)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.util.concurrent.TimeoutException: Cannot receive any reply from null in 120 seconds\n",
      "\t... 8 more\n",
      "23/06/30 04:25:31 WARN netty.NettyRpcEnv: Ignored failure: org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from null in 120 seconds. This timeout is controlled by spark.rpc.askTimeout\n"
     ]
    }
   ],
   "source": [
    "# Serializing json\n",
    "json_object = json.dumps(results_dict, indent=4)\n",
    " \n",
    "# Writing to sample.json\n",
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be87aa4-dd64-4a22-8a9f-66e1c5e12ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADH-USERS Python 3 + PySpark 2",
   "language": "python",
   "name": "python3-pyspark2-adh-users"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
