{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a64ec341-9ec8-4ba2-b1c9-a903ffee2b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn --force\n",
    "#!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "532f9d68-b0fc-4a7b-b166-b60981a74909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "pd.set_option('display.max.columns', 300)\n",
    "\n",
    "from core.calculator.storage import ModelDB\n",
    "from core.calculator.core import ForecastConfig\n",
    "from core.calculator.core import TrainingManager\n",
    "from core.calculator.core import ForecastConfig\n",
    "from core.calculator.core import ForecastEngine\n",
    "\n",
    "from core.calculator.deposits import DepositsCalculationType\n",
    "from core.calculator.deposits import DepositIterativeCalculator\n",
    "\n",
    "from core.definitions import *\n",
    "from core.project_update import load_portfolio\n",
    "\n",
    "from core.models import DepositModels\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9191a861-5357-4881-a639-2eacbd419624",
   "metadata": {},
   "source": [
    "## Корректируем таблицу по НС"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e725f9-e187-4bda-8d4e-485aa861ad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/22 18:44:23 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error\n",
      "23/10/22 18:44:24 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error\n",
      "23/10/22 18:44:25 WARN yarn.Client: Same path resource file:///opt/cloudera/parcels/AnacondaPy37/jars/spark-tree-plotting-0.2.jar added multiple times to distributed cache.\n",
      "23/10/22 18:44:38 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error\n",
      "23/10/22 18:44:38 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to request executors before the AM has registered!\n"
     ]
    }
   ],
   "source": [
    "# для создания табличек\n",
    "\n",
    "from core.models.utils import run_spark_session\n",
    "spark = run_spark_session('create_table_tnd_v2')\n",
    "\n",
    "#spark = None #если без обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "291f602d-ed4d-4c1c-8d52-98319dfd1ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"\"\"\n",
    "with cte \n",
    "as\n",
    "(\n",
    "SELECT \t\t\t\t\n",
    "    CAST (last_day(foa.ENTRY_DT) AS TIMESTAMP) AS REPORT_DT,\t\t\t\t\n",
    "    CAST (CASE WHEN product_bp_group_nm = 'Накопительные счета' THEN 'PR_SAAC' \t\t\t\t\n",
    "            WHEN product_bp_group_nm in ('Дебетовые Карты', 'Текущие счета') THEN 'PR_TC' \t\t\t\t\n",
    "            ELSE 'PR_DEP' END as varchar(50)) as PROD_smot,\t\t\t\t\n",
    "                    \t\t\t\t\n",
    "    CASE \t\t\t\t\n",
    "                WHEN FOA.PRODUCT_BP_GROUP_NM LIKE 'Депозиты%' THEN 'Депозиты'\t\t\t\t\n",
    "                WHEN FOA.PRODUCT_BP_CD = '300034' THEN 'Escrow' \t\t\t\t\n",
    "                WHEN FOA.PRODUCT_BP_CD IN ('303003', '393002') OR B.DEPOSIT_TYPE_CD = 'SA' THEN 'Накопительные'\t\t\n",
    "\t\t\t\tWHEN foa.PRODUCT_BP_GROUP_NM = 'Накопительные счета' THEN 'Накопительные'\n",
    "                WHEN SUBSTR(B.ACCOUNT_NUM,1,5) IN ('40901','40902') THEN 'Аккредитивы'\t\t\t\t\n",
    "                WHEN SUBSTR(B.ACCOUNT_NUM,1,5) = '52206' THEN 'Сберегательные сертификаты'\t\t\t\t\n",
    "                WHEN foa.PRODUCT_BP_GROUP_NM IS NULL THEN 'Депозиты'\t\t\t\t\n",
    "                ELSE 'Текущие' END AS PRODUCT_NM,    \t\t\t\t\n",
    "    FOA.PRODUCT_BANK_GROUP_NM,\t\t\t\t\n",
    "    FOA.PRODUCT_BP_GROUP_NM,\t\t\t\t\n",
    "    CASE WHEN B.CURRENCY_RK = 48 THEN 'RUR'\t\t\t\t\n",
    "                WHEN B.CURRENCY_RK = 60 THEN 'ЕUR'\t\n",
    "\t\t\t\tWHEN B.CURRENCY_RK = 8 THEN 'CNY'\n",
    "\t\t\t\tWHEN B.CURRENCY_RK IS NULL THEN 'RUR'\n",
    "                ELSE 'USD' END AS VAL_3,\t\t\t\t\n",
    "   \t\t\t\t\n",
    "    COALESCE (CUST.SERVICE_MODEL_CD, 'Массовый') AS MODEL,\t\t\t\t\n",
    "    CUST.SERVICE_MODEL_CD AS MODEL_DETAIL,\t\n",
    "                \t\t\t\t\n",
    "(cast(PROFIT_LOSSES_FLG as decimal(2,1))  * foa.ENTRY_RUR_AMT) as losses\t\t\t\t\n",
    "\t\t\t\t\n",
    "\t\t\t\t\n",
    "FROM CDM.FCT_OPERATION_ANALYTICS foa\t\t\t\t\n",
    "--\t\t\t\t\n",
    "LEFT JOIN CDM.CD_DEPOSIT b           \t\t\t\t\n",
    "        ON foa.AGREEMENT_RK=b.AGREEMENT_RK                        \t\t\t\t\n",
    "        AND b.DELETED_FLG='0'                        \t\t\t\t\n",
    "        AND CAST (foa.ENTRY_DT AS TIMESTAMP) BETWEEN b.EFFECTIVE_FROM_DTTM AND b.EFFECTIVE_TO_DTTM   \t\t\t\t\n",
    "--\t\t\t\t\n",
    "LEFT JOIN  CDM.TECH_CUSTOMER_X_GLOBAL AS C\t\t\t\t\n",
    "        ON foa.CUSTOMER_RK = C.CUSTOMER_RK  \t\t\t\t\n",
    "        AND C.CUSTOMER_GLOBAL_TYPE='MDM'\t\t\t\t\n",
    "        AND  C.EFFECTIVE_TO_DTTM = CAST('5999-12-31 00:00:00' AS TIMESTAMP)\t\t\t\t\n",
    "        AND C.DELETED_FLG='0'\t\t\t\t\n",
    "--\t\t\t\t\n",
    "LEFT JOIN CDM.CD_CUSTOMER_SERVICE CUST\t\t\t\t\n",
    "    ON CUST.CUSTOMER_GLOBAL_RK = C.CUSTOMER_GLOBAL_RK\t\t\t\t\n",
    "    AND CAST (last_day(foa.ENTRY_DT) AS TIMESTAMP)  BETWEEN CUST.EFFECTIVE_FROM_DTTM AND CUST.EFFECTIVE_TO_DTTM\t\t\t\t\n",
    "    AND CUST.IS_ACTIVE_FLG<>'2'\t\t\t\t\n",
    "    AND CUST.DELETED_FLG='0'\t\t\t\t\n",
    "--                \t\t\t\t\n",
    "WHERE 1=1\t\t\t\t\n",
    "        AND PNL_REPORT_CD='020'\t\n",
    "\t\tAND foa.PRODUCT_BP_GROUP_NM IN ('Дебетовые Карты', 'Депозиты', 'Накопительные счета', 'Текущие счета')\n",
    "    --    AND UPPER(foa.PRODUCT_BANK_GROUP_NM) IN ('РКО', 'ДЕПФЛ', 'РКПРОЧ', 'ВИП', 'ДЕБЕТОВЫЕ КАРТЫ') \t\t\t\t\n",
    "--AND foa.PRODUCT_CORE_FLG = 'Y'\t\t\t\t\n",
    "                        AND foa.ENTRY_DT BETWEEN CAST('2023-01-01' AS TIMESTAMP) AND CAST('2023-12-31' AS TIMESTAMP) \t\t\t\t\n",
    "                        AND foa.EFFECTIVE_TO_DTTM = CAST('5999-12-31 00:00:00' AS TIMESTAMP)\t\t\t\t\n",
    "                        AND foa.DELETED_FLG='0'\t\t\t\t\n",
    "                        AND IS_SPOD_FLG='0'\t\n",
    "\t\t\t\t\t\tAND FOA.IS_ACTIVE_FLG = '1'\n",
    "                        AND foa.PNL_ALGORITHM_CD = 'FOA_DIRECT_INT'\n",
    "\t\t\t\t\t\tAND FOA.SOURCE_SYSTEM_CD IN ('00000', '00002', '00006', '00018', '00040', '00051', '00055', '00056', '00072', '95013', '98000', '99995')\n",
    "--GROUP BY 1,2,3,4,5,6,7,8\t\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "select *\n",
    "from cte\n",
    "\t\t\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a471a93d-1980-4008-97ba-82ae70711c44",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o93.sql.\n: org.apache.hadoop.security.AccessControlException: Permission denied: user=vtb70186744, access=READ_EXECUTE, inode=\"/data/adwh/prod_rls/cd_deposit\":hive:hive:drwxrwx--x\n\tat org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:410)\n\tat org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:264)\n\tat org.apache.sentry.hdfs.SentryINodeAttributesProvider$SentryPermissionEnforcer.checkPermission(SentryINodeAttributesProvider.java:86)\n\tat org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:194)\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1875)\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1859)\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPathAccess(FSDirectory.java:1809)\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getListingInt(FSDirStatAndListingOp.java:79)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3746)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:1139)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:708)\n\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:869)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:815)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2674)\n\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)\n\tat org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)\n\tat org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1613)\n\tat org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1595)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:977)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.access$1000(DistributedFileSystem.java:122)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$24.doCall(DistributedFileSystem.java:1041)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$24.doCall(DistributedFileSystem.java:1038)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:1048)\n\tat com.wandisco.fs.client.ReplicatedFC.xlateAndListStatus(ReplicatedFC.java:320)\n\tat com.wandisco.fs.client.FusionHdfs.listStatus(FusionHdfs.java:430)\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:278)\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$bulkListLeafFiles$1.apply(InMemoryFileIndex.scala:175)\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$bulkListLeafFiles$1.apply(InMemoryFileIndex.scala:174)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.bulkListLeafFiles(InMemoryFileIndex.scala:174)\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex.listLeafFiles(InMemoryFileIndex.scala:127)\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex.refresh0(InMemoryFileIndex.scala:92)\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex.<init>(InMemoryFileIndex.scala:68)\n\tat org.apache.spark.sql.hive.HiveMetastoreCatalog$$anonfun$9.apply(HiveMetastoreCatalog.scala:235)\n\tat org.apache.spark.sql.hive.HiveMetastoreCatalog$$anonfun$9.apply(HiveMetastoreCatalog.scala:233)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.sql.hive.HiveMetastoreCatalog.org$apache$spark$sql$hive$HiveMetastoreCatalog$$inferIfNeeded(HiveMetastoreCatalog.scala:233)\n\tat org.apache.spark.sql.hive.HiveMetastoreCatalog$$anonfun$6$$anonfun$7.apply(HiveMetastoreCatalog.scala:193)\n\tat org.apache.spark.sql.hive.HiveMetastoreCatalog$$anonfun$6$$anonfun$7.apply(HiveMetastoreCatalog.scala:192)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.sql.hive.HiveMetastoreCatalog$$anonfun$6.apply(HiveMetastoreCatalog.scala:192)\n\tat org.apache.spark.sql.hive.HiveMetastoreCatalog$$anonfun$6.apply(HiveMetastoreCatalog.scala:185)\n\tat org.apache.spark.sql.hive.HiveMetastoreCatalog.withTableCreationLock(HiveMetastoreCatalog.scala:54)\n\tat org.apache.spark.sql.hive.HiveMetastoreCatalog.convertToLogicalRelation(HiveMetastoreCatalog.scala:185)\n\tat org.apache.spark.sql.hive.RelationConversions.org$apache$spark$sql$hive$RelationConversions$$convert(HiveStrategies.scala:207)\n\tat org.apache.spark.sql.hive.RelationConversions$$anonfun$apply$4.applyOrElse(HiveStrategies.scala:231)\n\tat org.apache.spark.sql.hive.RelationConversions$$anonfun$apply$4.applyOrElse(HiveStrategies.scala:220)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1$$anonfun$2.apply(AnalysisHelper.scala:108)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1$$anonfun$2.apply(AnalysisHelper.scala:108)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1.apply(AnalysisHelper.scala:107)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1.apply(AnalysisHelper.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsDown(AnalysisHelper.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDown(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1$$anonfun$apply$6.apply(AnalysisHelper.scala:113)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1$$anonfun$apply$6.apply(AnalysisHelper.scala:113)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1.apply(AnalysisHelper.scala:113)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1.apply(AnalysisHelper.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsDown(AnalysisHelper.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDown(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1$$anonfun$apply$6.apply(AnalysisHelper.scala:113)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1$$anonfun$apply$6.apply(AnalysisHelper.scala:113)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1.apply(AnalysisHelper.scala:113)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1.apply(AnalysisHelper.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsDown(AnalysisHelper.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDown(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperators(AnalysisHelper.scala:73)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.hive.RelationConversions.apply(HiveStrategies.scala:220)\n\tat org.apache.spark.sql.hive.RelationConversions.apply(HiveStrategies.scala:180)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:87)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:84)\n\tat scala.collection.IndexedSeqOptimized$class.foldl(IndexedSeqOptimized.scala:57)\n\tat scala.collection.IndexedSeqOptimized$class.foldLeft(IndexedSeqOptimized.scala:66)\n\tat scala.collection.mutable.ArrayBuffer.foldLeft(ArrayBuffer.scala:48)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:76)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:76)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:127)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$35.apply(Analyzer.scala:699)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$35.apply(Analyzer.scala:692)\n\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withAnalysisContext(Analyzer.scala:87)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:692)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:703)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:715)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:708)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:89)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:708)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:654)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:87)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:84)\n\tat scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)\n\tat scala.collection.immutable.List.foldLeft(List.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:76)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:76)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:127)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$35.apply(Analyzer.scala:699)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$35.apply(Analyzer.scala:692)\n\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withAnalysisContext(Analyzer.scala:87)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:692)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:703)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:715)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:708)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:89)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:708)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:654)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:87)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:84)\n\tat scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)\n\tat scala.collection.immutable.List.foldLeft(List.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:76)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:76)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:127)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$CTESubstitution$$anonfun$apply$1$$anonfun$applyOrElse$15.apply(Analyzer.scala:214)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$CTESubstitution$$anonfun$apply$1$$anonfun$applyOrElse$15.apply(Analyzer.scala:212)\n\tat scala.collection.IndexedSeqOptimized$class.foldl(IndexedSeqOptimized.scala:57)\n\tat scala.collection.IndexedSeqOptimized$class.foldLeft(IndexedSeqOptimized.scala:66)\n\tat scala.collection.mutable.ArrayBuffer.foldLeft(ArrayBuffer.scala:48)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$CTESubstitution$$anonfun$apply$1.applyOrElse(Analyzer.scala:212)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$CTESubstitution$$anonfun$apply$1.applyOrElse(Analyzer.scala:210)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:89)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$CTESubstitution$.apply(Analyzer.scala:210)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$CTESubstitution$.apply(Analyzer.scala:209)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:87)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:84)\n\tat scala.collection.IndexedSeqOptimized$class.foldl(IndexedSeqOptimized.scala:57)\n\tat scala.collection.IndexedSeqOptimized$class.foldLeft(IndexedSeqOptimized.scala:66)\n\tat scala.collection.mutable.WrappedArray.foldLeft(WrappedArray.scala:35)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:76)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:76)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:127)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:121)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:106)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:651)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=vtb70186744, access=READ_EXECUTE, inode=\"/data/adwh/prod_rls/cd_deposit\":hive:hive:drwxrwx--x\n\tat org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:410)\n\tat org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:264)\n\tat org.apache.sentry.hdfs.SentryINodeAttributesProvider$SentryPermissionEnforcer.checkPermission(SentryINodeAttributesProvider.java:86)\n\tat org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:194)\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1875)\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1859)\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPathAccess(FSDirectory.java:1809)\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getListingInt(FSDirStatAndListingOp.java:79)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3746)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:1139)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:708)\n\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:869)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:815)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2674)\n\n\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1508)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1454)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1364)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n\tat com.sun.proxy.$Proxy12.getListing(Unknown Source)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getListing(ClientNamenodeProtocolTranslatorPB.java:654)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n\tat com.sun.proxy.$Proxy13.getListing(Unknown Source)\n\tat org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1611)\n\t... 278 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5776/44079155.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/envs/hmelevskoi_env/lib/python3.7/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \"\"\"\n\u001b[0;32m--> 767\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/envs/hmelevskoi_env/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/envs/hmelevskoi_env/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/envs/hmelevskoi_env/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o93.sql.\n: org.apache.hadoop.security.AccessControlException: Permission denied: user=vtb70186744, access=READ_EXECUTE, inode=\"/data/adwh/prod_rls/cd_deposit\":hive:hive:drwxrwx--x\n\tat org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:410)\n\tat org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:264)\n\tat org.apache.sentry.hdfs.SentryINodeAttributesProvider$SentryPermissionEnforcer.checkPermission(SentryINodeAttributesProvider.java:86)\n\tat org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:194)\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1875)\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1859)\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPathAccess(FSDirectory.java:1809)\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getListingInt(FSDirStatAndListingOp.java:79)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3746)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:1139)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:708)\n\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:869)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:815)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2674)\n\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)\n\tat org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)\n\tat org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1613)\n\tat org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1595)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:977)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.access$1000(DistributedFileSystem.java:122)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$24.doCall(DistributedFileSystem.java:1041)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$24.doCall(DistributedFileSystem.java:1038)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:1048)\n\tat com.wandisco.fs.client.ReplicatedFC.xlateAndListStatus(ReplicatedFC.java:320)\n\tat com.wandisco.fs.client.FusionHdfs.listStatus(FusionHdfs.java:430)\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:278)\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$bulkListLeafFiles$1.apply(InMemoryFileIndex.scala:175)\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$bulkListLeafFiles$1.apply(InMemoryFileIndex.scala:174)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.bulkListLeafFiles(InMemoryFileIndex.scala:174)\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex.listLeafFiles(InMemoryFileIndex.scala:127)\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex.refresh0(InMemoryFileIndex.scala:92)\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex.<init>(InMemoryFileIndex.scala:68)\n\tat org.apache.spark.sql.hive.HiveMetastoreCatalog$$anonfun$9.apply(HiveMetastoreCatalog.scala:235)\n\tat org.apache.spark.sql.hive.HiveMetastoreCatalog$$anonfun$9.apply(HiveMetastoreCatalog.scala:233)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.sql.hive.HiveMetastoreCatalog.org$apache$spark$sql$hive$HiveMetastoreCatalog$$inferIfNeeded(HiveMetastoreCatalog.scala:233)\n\tat org.apache.spark.sql.hive.HiveMetastoreCatalog$$anonfun$6$$anonfun$7.apply(HiveMetastoreCatalog.scala:193)\n\tat org.apache.spark.sql.hive.HiveMetastoreCatalog$$anonfun$6$$anonfun$7.apply(HiveMetastoreCatalog.scala:192)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.sql.hive.HiveMetastoreCatalog$$anonfun$6.apply(HiveMetastoreCatalog.scala:192)\n\tat org.apache.spark.sql.hive.HiveMetastoreCatalog$$anonfun$6.apply(HiveMetastoreCatalog.scala:185)\n\tat org.apache.spark.sql.hive.HiveMetastoreCatalog.withTableCreationLock(HiveMetastoreCatalog.scala:54)\n\tat org.apache.spark.sql.hive.HiveMetastoreCatalog.convertToLogicalRelation(HiveMetastoreCatalog.scala:185)\n\tat org.apache.spark.sql.hive.RelationConversions.org$apache$spark$sql$hive$RelationConversions$$convert(HiveStrategies.scala:207)\n\tat org.apache.spark.sql.hive.RelationConversions$$anonfun$apply$4.applyOrElse(HiveStrategies.scala:231)\n\tat org.apache.spark.sql.hive.RelationConversions$$anonfun$apply$4.applyOrElse(HiveStrategies.scala:220)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1$$anonfun$2.apply(AnalysisHelper.scala:108)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1$$anonfun$2.apply(AnalysisHelper.scala:108)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1.apply(AnalysisHelper.scala:107)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1.apply(AnalysisHelper.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsDown(AnalysisHelper.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDown(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1$$anonfun$apply$6.apply(AnalysisHelper.scala:113)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1$$anonfun$apply$6.apply(AnalysisHelper.scala:113)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1.apply(AnalysisHelper.scala:113)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1.apply(AnalysisHelper.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsDown(AnalysisHelper.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDown(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1$$anonfun$apply$6.apply(AnalysisHelper.scala:113)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1$$anonfun$apply$6.apply(AnalysisHelper.scala:113)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1.apply(AnalysisHelper.scala:113)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1.apply(AnalysisHelper.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsDown(AnalysisHelper.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDown(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperators(AnalysisHelper.scala:73)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.hive.RelationConversions.apply(HiveStrategies.scala:220)\n\tat org.apache.spark.sql.hive.RelationConversions.apply(HiveStrategies.scala:180)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:87)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:84)\n\tat scala.collection.IndexedSeqOptimized$class.foldl(IndexedSeqOptimized.scala:57)\n\tat scala.collection.IndexedSeqOptimized$class.foldLeft(IndexedSeqOptimized.scala:66)\n\tat scala.collection.mutable.ArrayBuffer.foldLeft(ArrayBuffer.scala:48)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:76)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:76)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:127)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$35.apply(Analyzer.scala:699)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$35.apply(Analyzer.scala:692)\n\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withAnalysisContext(Analyzer.scala:87)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:692)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:703)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:715)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:708)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:89)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:708)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:654)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:87)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:84)\n\tat scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)\n\tat scala.collection.immutable.List.foldLeft(List.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:76)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:76)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:127)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$35.apply(Analyzer.scala:699)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$35.apply(Analyzer.scala:692)\n\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withAnalysisContext(Analyzer.scala:87)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:692)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:703)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:715)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:708)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:89)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:708)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:654)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:87)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:84)\n\tat scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)\n\tat scala.collection.immutable.List.foldLeft(List.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:76)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:76)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:127)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$CTESubstitution$$anonfun$apply$1$$anonfun$applyOrElse$15.apply(Analyzer.scala:214)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$CTESubstitution$$anonfun$apply$1$$anonfun$applyOrElse$15.apply(Analyzer.scala:212)\n\tat scala.collection.IndexedSeqOptimized$class.foldl(IndexedSeqOptimized.scala:57)\n\tat scala.collection.IndexedSeqOptimized$class.foldLeft(IndexedSeqOptimized.scala:66)\n\tat scala.collection.mutable.ArrayBuffer.foldLeft(ArrayBuffer.scala:48)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$CTESubstitution$$anonfun$apply$1.applyOrElse(Analyzer.scala:212)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$CTESubstitution$$anonfun$apply$1.applyOrElse(Analyzer.scala:210)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:89)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$CTESubstitution$.apply(Analyzer.scala:210)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$CTESubstitution$.apply(Analyzer.scala:209)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:87)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:84)\n\tat scala.collection.IndexedSeqOptimized$class.foldl(IndexedSeqOptimized.scala:57)\n\tat scala.collection.IndexedSeqOptimized$class.foldLeft(IndexedSeqOptimized.scala:66)\n\tat scala.collection.mutable.WrappedArray.foldLeft(WrappedArray.scala:35)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:76)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:76)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:127)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:121)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:106)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:651)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=vtb70186744, access=READ_EXECUTE, inode=\"/data/adwh/prod_rls/cd_deposit\":hive:hive:drwxrwx--x\n\tat org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:410)\n\tat org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:264)\n\tat org.apache.sentry.hdfs.SentryINodeAttributesProvider$SentryPermissionEnforcer.checkPermission(SentryINodeAttributesProvider.java:86)\n\tat org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:194)\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1875)\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1859)\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPathAccess(FSDirectory.java:1809)\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getListingInt(FSDirStatAndListingOp.java:79)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3746)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:1139)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:708)\n\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:869)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:815)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2674)\n\n\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1508)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1454)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1364)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n\tat com.sun.proxy.$Proxy12.getListing(Unknown Source)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getListing(ClientNamenodeProtocolTranslatorPB.java:654)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n\tat com.sun.proxy.$Proxy13.getListing(Unknown Source)\n\tat org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1611)\n\t... 278 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/23 06:44:44 ERROR cluster.YarnClientSchedulerBackend: YARN application has exited unexpectedly with state SUCCEEDED! Check the YARN application logs for more details.\n",
      "23/10/23 06:46:57 ERROR util.Utils: Uncaught exception in thread YARN application state monitor\n",
      "org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [120 seconds]. This timeout is controlled by spark.rpc.askTimeout\n",
      "\tat org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)\n",
      "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.requestTotalExecutors(CoarseGrainedSchedulerBackend.scala:594)\n",
      "\tat org.apache.spark.scheduler.cluster.YarnSchedulerBackend.stop(YarnSchedulerBackend.scala:98)\n",
      "\tat org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.stop(YarnClientSchedulerBackend.scala:165)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:653)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2079)\n",
      "\tat org.apache.spark.SparkContext$$anonfun$stop$7.apply$mcV$sp(SparkContext.scala:1963)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1388)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:1962)\n",
      "\tat org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend$MonitorThread.run(YarnClientSchedulerBackend.scala:122)\n",
      "Caused by: java.util.concurrent.TimeoutException: Futures timed out after [120 seconds]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:223)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:227)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:220)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\t... 9 more\n",
      "23/10/23 06:46:57 ERROR cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(0,0,Map(),Set()) to AM was unsuccessful\n",
      "org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from null in 120 seconds. This timeout is controlled by spark.rpc.askTimeout\n",
      "\tat org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)\n",
      "\tat scala.util.Failure$$anonfun$recover$1.apply(Try.scala:216)\n",
      "\tat scala.util.Try$.apply(Try.scala:192)\n",
      "\tat scala.util.Failure.recover(Try.scala:216)\n",
      "\tat scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)\n",
      "\tat scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:36)\n",
      "\tat org.spark_project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:44)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:252)\n",
      "\tat scala.concurrent.Promise$class.complete(Promise.scala:55)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:157)\n",
      "\tat scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)\n",
      "\tat scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:36)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.processBatch$1(BatchingExecutor.scala:63)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:78)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:54)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:601)\n",
      "\tat scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:106)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:599)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:44)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:252)\n",
      "\tat scala.concurrent.Promise$class.tryFailure(Promise.scala:112)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:157)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:206)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:243)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.util.concurrent.TimeoutException: Cannot receive any reply from null in 120 seconds\n",
      "\t... 8 more\n"
     ]
    }
   ],
   "source": [
    "df_table = spark.sql(query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63013f93-60de-454d-9e36-46a0cf3e9b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1595362-5a86-4157-b612-4bd62ab38b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d75ccd-59ea-4e18-8708-ab55e7f25ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03afbdb4-4a01-4c24-8172-b8d3dec2a3d0",
   "metadata": {},
   "source": [
    "## Калькулятор маржи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72be3b50-06d0-4ee2-b9e3-515a4233b5b4",
   "metadata": {},
   "source": [
    "Внутренняя стоимость средств на накопительных счетах (ВССНС) ФЛ в рублях  \n",
    "устанавливается в виде фиксированной ставки как сумма значения Ключевой  \n",
    "ставки Банка России и надбавки, равной среднекалендарному значению  \n",
    "трансфертной ставки в рублях на базе КС на срок 1 год за предшествующие дате  \n",
    "расчета 1095 дней (с учетом выходных и праздничных дней).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11baf3cb-5a31-4c9f-be36-8a1cfe419cf5",
   "metadata": {},
   "source": [
    "## Рассмотрим weighted_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f5584b54-8eba-4e9b-8b1f-d069f2e20d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_rates = pd.read_csv('SA_rates_table_v4_prod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0eb8c67a-7e43-49c6-b04e-1d05f36a9c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_rates.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b4d8f630-a7f2-4542-b1bb-805d313632fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_rates['weighted_rate_x_balance'] = data_rates['weighted_rate'] * data_rates['balance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6d384ccd-8a34-4872-a1d7-fb12c06808e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_rates.groupby('report_date').sum()['weighted_rate_x_balance'] / data_rates.groupby('report_date').sum()['balance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f75c547-5212-4f53-9e58-e805d5160f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba7dbfc8-e456-471b-9fd5-9f453e7902fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_rates['report_dt'] = data_rates['report_year'].astype(str) + '-' + data_rates['report_month'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ef0536-e290-4205-af52-04206b91b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_rates['avg_rate_x_avg_balance'] = data_rates['avg_rate'] * data_rates['avg_balance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9da54b-4dc3-4860-b38e-9401d00e2c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_rates.groupby('report_dt').sum()['avg_rate_x_avg_balance'] / data_rates.groupby('report_dt').sum()['avg_balance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d6f311-ab51-4032-8ead-f13f7191e1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_rates['avg_weighted_rate_x_avg_balance'] = data_rates['avg_weighted_rate'] * data_rates['avg_balance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "919fc497-a11a-45ef-a145-4f6c7cbfdb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_rates.groupby(['report_dt', 'is_vip_or_prv']).sum()['avg_weighted_rate_x_avg_balance'] / data_rates.groupby(['report_dt', 'is_vip_or_prv']).sum()['avg_balance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695942d0-c97b-40b8-8e28-21edd7b1bfd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ab01d-2458-40f5-8efe-4de781980db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4ee440-5306-442e-919d-5b1c94805dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93f69de7-dd65-41fc-9bfa-a8861eab35db",
   "metadata": {},
   "source": [
    "## Смотрим расчет по балансу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd2f73da-ccdb-46bc-84ab-d1ae5599ae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_fact = pd.read_csv('saving_accounts_fact.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7926797f-3806-4a1d-99a2-91f3e0fb34cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_fact = sa_fact[(sa_fact['report_dt']>='2023-01-01')&(sa_fact['report_dt']<='2023-08-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "659e29b6-a1fe-43c0-93a3-e2d4e56039f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_dt</th>\n",
       "      <th>balance_general</th>\n",
       "      <th>sa_avg_balance_[general]_[mass]</th>\n",
       "      <th>sa_avg_balance_[general]_[priv]</th>\n",
       "      <th>sa_avg_balance_[general]_[vip]</th>\n",
       "      <th>sa_weighted_rate_[general]_[mass]</th>\n",
       "      <th>sa_weighted_rate_[general]_[priv]</th>\n",
       "      <th>sa_weighted_rate_[general]_[vip]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-31 00:00:00</td>\n",
       "      <td>1.208002e+12</td>\n",
       "      <td>7.893295e+11</td>\n",
       "      <td>3.842425e+11</td>\n",
       "      <td>3.443007e+10</td>\n",
       "      <td>5.578756</td>\n",
       "      <td>5.085335</td>\n",
       "      <td>4.810358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-30 00:00:00</td>\n",
       "      <td>1.166320e+12</td>\n",
       "      <td>7.596419e+11</td>\n",
       "      <td>3.728167e+11</td>\n",
       "      <td>3.386101e+10</td>\n",
       "      <td>5.497468</td>\n",
       "      <td>5.075955</td>\n",
       "      <td>4.733183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-05-31 00:00:00</td>\n",
       "      <td>1.112985e+12</td>\n",
       "      <td>7.413980e+11</td>\n",
       "      <td>3.403776e+11</td>\n",
       "      <td>3.120987e+10</td>\n",
       "      <td>5.396878</td>\n",
       "      <td>5.044873</td>\n",
       "      <td>4.737019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-30 00:00:00</td>\n",
       "      <td>1.095063e+12</td>\n",
       "      <td>7.248563e+11</td>\n",
       "      <td>3.392324e+11</td>\n",
       "      <td>3.097406e+10</td>\n",
       "      <td>5.305644</td>\n",
       "      <td>5.001618</td>\n",
       "      <td>4.744042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-03-31 00:00:00</td>\n",
       "      <td>1.083712e+12</td>\n",
       "      <td>7.098920e+11</td>\n",
       "      <td>3.429391e+11</td>\n",
       "      <td>3.088107e+10</td>\n",
       "      <td>5.130050</td>\n",
       "      <td>4.904298</td>\n",
       "      <td>4.714634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-02-28 00:00:00</td>\n",
       "      <td>1.084683e+12</td>\n",
       "      <td>7.058291e+11</td>\n",
       "      <td>3.417648e+11</td>\n",
       "      <td>3.708912e+10</td>\n",
       "      <td>5.076594</td>\n",
       "      <td>4.871131</td>\n",
       "      <td>4.686045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-01-31 00:00:00</td>\n",
       "      <td>1.087555e+12</td>\n",
       "      <td>7.029266e+11</td>\n",
       "      <td>3.503515e+11</td>\n",
       "      <td>3.427652e+10</td>\n",
       "      <td>5.028761</td>\n",
       "      <td>4.852665</td>\n",
       "      <td>4.687145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             report_dt  balance_general  sa_avg_balance_[general]_[mass]  \\\n",
       "1  2023-07-31 00:00:00     1.208002e+12                     7.893295e+11   \n",
       "2  2023-06-30 00:00:00     1.166320e+12                     7.596419e+11   \n",
       "3  2023-05-31 00:00:00     1.112985e+12                     7.413980e+11   \n",
       "4  2023-04-30 00:00:00     1.095063e+12                     7.248563e+11   \n",
       "5  2023-03-31 00:00:00     1.083712e+12                     7.098920e+11   \n",
       "6  2023-02-28 00:00:00     1.084683e+12                     7.058291e+11   \n",
       "7  2023-01-31 00:00:00     1.087555e+12                     7.029266e+11   \n",
       "\n",
       "   sa_avg_balance_[general]_[priv]  sa_avg_balance_[general]_[vip]  \\\n",
       "1                     3.842425e+11                    3.443007e+10   \n",
       "2                     3.728167e+11                    3.386101e+10   \n",
       "3                     3.403776e+11                    3.120987e+10   \n",
       "4                     3.392324e+11                    3.097406e+10   \n",
       "5                     3.429391e+11                    3.088107e+10   \n",
       "6                     3.417648e+11                    3.708912e+10   \n",
       "7                     3.503515e+11                    3.427652e+10   \n",
       "\n",
       "   sa_weighted_rate_[general]_[mass]  sa_weighted_rate_[general]_[priv]  \\\n",
       "1                           5.578756                           5.085335   \n",
       "2                           5.497468                           5.075955   \n",
       "3                           5.396878                           5.044873   \n",
       "4                           5.305644                           5.001618   \n",
       "5                           5.130050                           4.904298   \n",
       "6                           5.076594                           4.871131   \n",
       "7                           5.028761                           4.852665   \n",
       "\n",
       "   sa_weighted_rate_[general]_[vip]  \n",
       "1                          4.810358  \n",
       "2                          4.733183  \n",
       "3                          4.737019  \n",
       "4                          4.744042  \n",
       "5                          4.714634  \n",
       "6                          4.686045  \n",
       "7                          4.687145  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_fact.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bd937cc-0ea9-4f7c-bcb7-55cbe3daaaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sa_fact.to_excel('sa_fact.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "536306c9-fcba-48a0-91ef-64bc8fc18c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_fact['sa_weighted_rate_general'] = (sa_fact['sa_avg_balance_[general]_[mass]'] * sa_fact['sa_weighted_rate_[general]_[mass]'] \\\n",
    "+ sa_fact['sa_avg_balance_[general]_[priv]'] * sa_fact['sa_weighted_rate_[general]_[priv]'] \\\n",
    "+ sa_fact['sa_avg_balance_[general]_[vip]'] * sa_fact['sa_weighted_rate_[general]_[vip]']) / sa_fact['balance_general']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbda6a87-d359-4f52-a50b-0fb7dbeb89bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_fact['date'] = sa_fact['report_dt'].apply(lambda x: x[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1344c141-31c0-4f4e-9c80-14c3d1127d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7238ac7b-735f-4b0a-ac31-27d269bb5ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip.main(['install', 'openpyxl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a97bcf9b-ab45-4f09-bded-ee147981b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7088b5a-2af5-49f6-b4e1-65a915efe198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5187165e-a5dc-4134-8b88-f4a606acd53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_ftp = pd.read_excel('sa_ftp_rates.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2feba59-ea03-40b6-86e2-6a47229fc8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Дата</th>\n",
       "      <th>Валюта</th>\n",
       "      <th>Инструмент</th>\n",
       "      <th>До востребования</th>\n",
       "      <th>Комментарий</th>\n",
       "      <th>Обозначение базиса плавающей ставки</th>\n",
       "      <th>Обозначение инструмента</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-18</td>\n",
       "      <td>RUB</td>\n",
       "      <td>Внутренняя стоимость средств на накопительных ...</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>Ставки утверждены Решением ФК от 15/09/2023</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>ODIP_SAV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-18</td>\n",
       "      <td>USD</td>\n",
       "      <td>Внутренняя стоимость средств на накопительных ...</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>Ставки утверждены Решением ФК от 15/09/2023</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>ODIP_SAV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-18</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Внутренняя стоимость средств на накопительных ...</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>Ставки утверждены Решением ФК от 15/09/2023</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>ODIP_SAV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-08-15</td>\n",
       "      <td>RUB</td>\n",
       "      <td>Внутренняя стоимость средств на накопительных ...</td>\n",
       "      <td>0.1274</td>\n",
       "      <td>Ставки утверждены Решением ФК</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>ODIP_SAV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-08-15</td>\n",
       "      <td>USD</td>\n",
       "      <td>Внутренняя стоимость средств на накопительных ...</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>Ставки утверждены Решением ФК</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>ODIP_SAV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Дата Валюта                                         Инструмент  \\\n",
       "0 2023-09-18    RUB  Внутренняя стоимость средств на накопительных ...   \n",
       "1 2023-09-18    USD  Внутренняя стоимость средств на накопительных ...   \n",
       "2 2023-09-18    EUR  Внутренняя стоимость средств на накопительных ...   \n",
       "3 2023-08-15    RUB  Внутренняя стоимость средств на накопительных ...   \n",
       "4 2023-08-15    USD  Внутренняя стоимость средств на накопительных ...   \n",
       "\n",
       "   До востребования                                  Комментарий  \\\n",
       "0            0.1374  Ставки утверждены Решением ФК от 15/09/2023   \n",
       "1            0.0162  Ставки утверждены Решением ФК от 15/09/2023   \n",
       "2            0.0162  Ставки утверждены Решением ФК от 15/09/2023   \n",
       "3            0.1274                Ставки утверждены Решением ФК   \n",
       "4            0.0153                Ставки утверждены Решением ФК   \n",
       "\n",
       "  Обозначение базиса плавающей ставки Обозначение инструмента  \n",
       "0                               Fixed                ODIP_SAV  \n",
       "1                               Fixed                ODIP_SAV  \n",
       "2                               Fixed                ODIP_SAV  \n",
       "3                               Fixed                ODIP_SAV  \n",
       "4                               Fixed                ODIP_SAV  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_ftp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3232b16a-77bf-450e-813d-2c9ffc63bee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_ftp = sa_ftp[(sa_ftp['Валюта']=='RUB')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f64df4e-51ef-43a8-902f-22cce5cad1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_ftp['До востребования'][sa_ftp['Дата']=='2023-07-24'] = 0.085"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52a98f95-2e50-46cd-9fcb-d656f5b4129e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    0.085\n",
       "Name: До востребования, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_ftp[sa_ftp['Дата']=='2023-07-24']['До востребования']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62551c43-182a-46ab-b40a-bdf75b1c39a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_ftp['date'] = sa_ftp['Дата'].apply(lambda x: str(x)[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1533d60c-a00c-40f1-9acb-77124c5a1d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_ftp.rename(columns={'До востребования': 'ftp_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcdbe18d-94f3-4382-918b-c4d63c2e2dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_ftp = sa_ftp[['date', 'ftp_rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ba92799-124e-4b7a-8bc0-d28257fe42c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_fact = sa_fact.merge(sa_ftp, on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5fe0593-348d-4ad6-a82f-4520b48f9ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_fact['ftp_rate'] = sa_fact['ftp_rate']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc683ab3-fe3b-4687-9641-67bd95cf3e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_dt</th>\n",
       "      <th>balance_general</th>\n",
       "      <th>sa_avg_balance_[general]_[mass]</th>\n",
       "      <th>sa_avg_balance_[general]_[priv]</th>\n",
       "      <th>sa_avg_balance_[general]_[vip]</th>\n",
       "      <th>sa_weighted_rate_[general]_[mass]</th>\n",
       "      <th>sa_weighted_rate_[general]_[priv]</th>\n",
       "      <th>sa_weighted_rate_[general]_[vip]</th>\n",
       "      <th>sa_weighted_rate_general</th>\n",
       "      <th>date</th>\n",
       "      <th>ftp_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-31 00:00:00</td>\n",
       "      <td>1.208002e+12</td>\n",
       "      <td>7.893295e+11</td>\n",
       "      <td>3.842425e+11</td>\n",
       "      <td>3.443007e+10</td>\n",
       "      <td>5.578756</td>\n",
       "      <td>5.085335</td>\n",
       "      <td>4.810358</td>\n",
       "      <td>5.399908</td>\n",
       "      <td>2023-07</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-30 00:00:00</td>\n",
       "      <td>1.166320e+12</td>\n",
       "      <td>7.596419e+11</td>\n",
       "      <td>3.728167e+11</td>\n",
       "      <td>3.386101e+10</td>\n",
       "      <td>5.497468</td>\n",
       "      <td>5.075955</td>\n",
       "      <td>4.733183</td>\n",
       "      <td>5.340541</td>\n",
       "      <td>2023-06</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-31 00:00:00</td>\n",
       "      <td>1.112985e+12</td>\n",
       "      <td>7.413980e+11</td>\n",
       "      <td>3.403776e+11</td>\n",
       "      <td>3.120987e+10</td>\n",
       "      <td>5.396878</td>\n",
       "      <td>5.044873</td>\n",
       "      <td>4.737019</td>\n",
       "      <td>5.270723</td>\n",
       "      <td>2023-05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-30 00:00:00</td>\n",
       "      <td>1.095063e+12</td>\n",
       "      <td>7.248563e+11</td>\n",
       "      <td>3.392324e+11</td>\n",
       "      <td>3.097406e+10</td>\n",
       "      <td>5.305644</td>\n",
       "      <td>5.001618</td>\n",
       "      <td>4.744042</td>\n",
       "      <td>5.195577</td>\n",
       "      <td>2023-04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-31 00:00:00</td>\n",
       "      <td>1.083712e+12</td>\n",
       "      <td>7.098920e+11</td>\n",
       "      <td>3.429391e+11</td>\n",
       "      <td>3.088107e+10</td>\n",
       "      <td>5.130050</td>\n",
       "      <td>4.904298</td>\n",
       "      <td>4.714634</td>\n",
       "      <td>5.046774</td>\n",
       "      <td>2023-03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             report_dt  balance_general  sa_avg_balance_[general]_[mass]  \\\n",
       "0  2023-07-31 00:00:00     1.208002e+12                     7.893295e+11   \n",
       "1  2023-06-30 00:00:00     1.166320e+12                     7.596419e+11   \n",
       "2  2023-05-31 00:00:00     1.112985e+12                     7.413980e+11   \n",
       "3  2023-04-30 00:00:00     1.095063e+12                     7.248563e+11   \n",
       "4  2023-03-31 00:00:00     1.083712e+12                     7.098920e+11   \n",
       "\n",
       "   sa_avg_balance_[general]_[priv]  sa_avg_balance_[general]_[vip]  \\\n",
       "0                     3.842425e+11                    3.443007e+10   \n",
       "1                     3.728167e+11                    3.386101e+10   \n",
       "2                     3.403776e+11                    3.120987e+10   \n",
       "3                     3.392324e+11                    3.097406e+10   \n",
       "4                     3.429391e+11                    3.088107e+10   \n",
       "\n",
       "   sa_weighted_rate_[general]_[mass]  sa_weighted_rate_[general]_[priv]  \\\n",
       "0                           5.578756                           5.085335   \n",
       "1                           5.497468                           5.075955   \n",
       "2                           5.396878                           5.044873   \n",
       "3                           5.305644                           5.001618   \n",
       "4                           5.130050                           4.904298   \n",
       "\n",
       "   sa_weighted_rate_[general]_[vip]  sa_weighted_rate_general     date  \\\n",
       "0                          4.810358                  5.399908  2023-07   \n",
       "1                          4.733183                  5.340541  2023-06   \n",
       "2                          4.737019                  5.270723  2023-05   \n",
       "3                          4.744042                  5.195577  2023-04   \n",
       "4                          4.714634                  5.046774  2023-03   \n",
       "\n",
       "   ftp_rate  \n",
       "0      8.50  \n",
       "1      8.26  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_fact.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0af3c4d7-76e0-4463-a59b-6292209d831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_fact['sa_weighted_rate_general'] = sa_fact['sa_weighted_rate_[general]_[vip]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d84c6b-71e5-45b2-9f85-098ae43295a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1679ac0f-edf6-447d-993f-006fe624bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSV = 0.48\n",
    "FOR = [4.5, 4.5, 4, 4, 4, 3, 3]\n",
    "WR = [4.897288112, 4.886817698, 4.869371293, 4.851317322, 4.83055387, 4.829810658, 4.826585737]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "526a8d0e-f8a2-41d5-b5b8-461e2402cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_fact['ftp_rate'] = sa_fact['ftp_rate'].fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1498811d-c9bc-49b5-93b7-cbf5f0f90472",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_fact['weighted_rate_calc'] = WR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "848225fb-98e1-452b-a433-a3af773e9069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8.50\n",
       "1    8.26\n",
       "2    8.18\n",
       "3    8.18\n",
       "4    8.18\n",
       "5    8.18\n",
       "6    8.18\n",
       "Name: ftp_rate, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_fact['ftp_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "44434652-b97d-4b89-8986-1963c4209f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.897288\n",
       "1    4.886818\n",
       "2    4.869371\n",
       "3    4.851317\n",
       "4    4.830554\n",
       "5    4.829811\n",
       "6    4.826586\n",
       "Name: weighted_rate_calc, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_fact['weighted_rate_calc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a7d7883-2b81-4275-93d6-19003154fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wr_day = sa_fact['sa_weighted_rate_general']**(1/365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3467831-3ad2-4769-b12e-4b1b7cb17d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#((wr_day)**(sa_fact['report_dt'].apply(lambda x: int(x[8:10])))-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4877e683-a9c3-4e47-a11f-c75273b0f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftp = sa_fact['ftp_rate'] * (1- pd.Series(FOR) / 100) - SSV - sa_fact['weighted_rate_calc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f261f9ec-1a02-4878-a903-e8cea5366b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.955\n",
       "1    0.955\n",
       "2    0.960\n",
       "3    0.960\n",
       "4    0.960\n",
       "5    0.970\n",
       "6    0.970\n",
       "dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1- pd.Series(FOR) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "671e6ed4-e42d-4ab4-879b-3dad0b2c68de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.740212\n",
       "1    2.521482\n",
       "2    2.503429\n",
       "3    2.521483\n",
       "4    2.542246\n",
       "5    2.624789\n",
       "6    2.628014\n",
       "dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "353e2a0a-0643-418c-9cb6-eaee6d5c8928",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftp_month = ((1+ftp/100)**(1/12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c8155fe9-9eab-4cac-b7fe-6c50c8cb46df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.002255\n",
       "1    1.002077\n",
       "2    1.002063\n",
       "3    1.002077\n",
       "4    1.002094\n",
       "5    1.002161\n",
       "6    1.002164\n",
       "dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftp_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2344ab55-a2c0-46d0-851a-d7647dc77fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftp_day = ((1+ftp/100)**(1/365))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7accefb2-539e-4ed2-91f2-29ed1198be35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.002299\n",
       "1    0.002049\n",
       "2    0.002102\n",
       "3    0.002049\n",
       "4    0.002134\n",
       "5    0.001990\n",
       "6    0.002206\n",
       "dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((ftp_day)**(sa_fact['report_dt'].apply(lambda x: int(x[8:10])))-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e3ad7ec1-13d6-4224-8082-539606978c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_fact['ftp_month'] = ftp_month -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4a59bd65-bec8-49e2-9cdb-1bd64e9eefcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_fact['ftp_month'] = sa_fact['ftp_month'].fillna(method='bfill').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f212e288-d701-474b-9d5d-8cc608be3f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_dt</th>\n",
       "      <th>balance_general</th>\n",
       "      <th>sa_avg_balance_[general]_[mass]</th>\n",
       "      <th>sa_avg_balance_[general]_[priv]</th>\n",
       "      <th>sa_avg_balance_[general]_[vip]</th>\n",
       "      <th>sa_weighted_rate_[general]_[mass]</th>\n",
       "      <th>sa_weighted_rate_[general]_[priv]</th>\n",
       "      <th>sa_weighted_rate_[general]_[vip]</th>\n",
       "      <th>sa_weighted_rate_general</th>\n",
       "      <th>date</th>\n",
       "      <th>ftp_rate</th>\n",
       "      <th>ftp_month</th>\n",
       "      <th>margin_general</th>\n",
       "      <th>margin_mass</th>\n",
       "      <th>margin_priv</th>\n",
       "      <th>margin_vip</th>\n",
       "      <th>weighted_rate_calc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-31 00:00:00</td>\n",
       "      <td>1.208002e+12</td>\n",
       "      <td>7.893295e+11</td>\n",
       "      <td>3.842425e+11</td>\n",
       "      <td>3.443007e+10</td>\n",
       "      <td>5.578756</td>\n",
       "      <td>5.085335</td>\n",
       "      <td>4.810358</td>\n",
       "      <td>4.810358</td>\n",
       "      <td>2023-07</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>2.863719e+09</td>\n",
       "      <td>1.871204e+09</td>\n",
       "      <td>9.108947e+08</td>\n",
       "      <td>8.162076e+07</td>\n",
       "      <td>4.897288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-30 00:00:00</td>\n",
       "      <td>1.166320e+12</td>\n",
       "      <td>7.596419e+11</td>\n",
       "      <td>3.728167e+11</td>\n",
       "      <td>3.386101e+10</td>\n",
       "      <td>5.497468</td>\n",
       "      <td>5.075955</td>\n",
       "      <td>4.733183</td>\n",
       "      <td>4.733183</td>\n",
       "      <td>2023-06</td>\n",
       "      <td>8.26</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>2.533464e+09</td>\n",
       "      <td>1.650084e+09</td>\n",
       "      <td>8.098277e+08</td>\n",
       "      <td>7.355244e+07</td>\n",
       "      <td>4.886818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-31 00:00:00</td>\n",
       "      <td>1.112985e+12</td>\n",
       "      <td>7.413980e+11</td>\n",
       "      <td>3.403776e+11</td>\n",
       "      <td>3.120987e+10</td>\n",
       "      <td>5.396878</td>\n",
       "      <td>5.044873</td>\n",
       "      <td>4.737019</td>\n",
       "      <td>4.737019</td>\n",
       "      <td>2023-05</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>2.461988e+09</td>\n",
       "      <td>1.640015e+09</td>\n",
       "      <td>7.529347e+08</td>\n",
       "      <td>6.903803e+07</td>\n",
       "      <td>4.869371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-30 00:00:00</td>\n",
       "      <td>1.095063e+12</td>\n",
       "      <td>7.248563e+11</td>\n",
       "      <td>3.392324e+11</td>\n",
       "      <td>3.097406e+10</td>\n",
       "      <td>5.305644</td>\n",
       "      <td>5.001618</td>\n",
       "      <td>4.744042</td>\n",
       "      <td>4.744042</td>\n",
       "      <td>2023-04</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>2.337946e+09</td>\n",
       "      <td>1.547560e+09</td>\n",
       "      <td>7.242572e+08</td>\n",
       "      <td>6.612926e+07</td>\n",
       "      <td>4.851317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-31 00:00:00</td>\n",
       "      <td>1.083712e+12</td>\n",
       "      <td>7.098920e+11</td>\n",
       "      <td>3.429391e+11</td>\n",
       "      <td>3.088107e+10</td>\n",
       "      <td>5.130050</td>\n",
       "      <td>4.904298</td>\n",
       "      <td>4.714634</td>\n",
       "      <td>4.714634</td>\n",
       "      <td>2023-03</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>2.417350e+09</td>\n",
       "      <td>1.583499e+09</td>\n",
       "      <td>7.649669e+08</td>\n",
       "      <td>6.888395e+07</td>\n",
       "      <td>4.830554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-02-28 00:00:00</td>\n",
       "      <td>1.084683e+12</td>\n",
       "      <td>7.058291e+11</td>\n",
       "      <td>3.417648e+11</td>\n",
       "      <td>3.708912e+10</td>\n",
       "      <td>5.076594</td>\n",
       "      <td>4.871131</td>\n",
       "      <td>4.686045</td>\n",
       "      <td>4.686045</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>2.274744e+09</td>\n",
       "      <td>1.480230e+09</td>\n",
       "      <td>7.167325e+08</td>\n",
       "      <td>7.778149e+07</td>\n",
       "      <td>4.829811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-31 00:00:00</td>\n",
       "      <td>1.087555e+12</td>\n",
       "      <td>7.029266e+11</td>\n",
       "      <td>3.503515e+11</td>\n",
       "      <td>3.427652e+10</td>\n",
       "      <td>5.028761</td>\n",
       "      <td>4.852665</td>\n",
       "      <td>4.687145</td>\n",
       "      <td>4.687145</td>\n",
       "      <td>2023-01</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>2.524427e+09</td>\n",
       "      <td>1.631630e+09</td>\n",
       "      <td>8.132341e+08</td>\n",
       "      <td>7.956249e+07</td>\n",
       "      <td>4.826586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             report_dt  balance_general  sa_avg_balance_[general]_[mass]  \\\n",
       "0  2023-07-31 00:00:00     1.208002e+12                     7.893295e+11   \n",
       "1  2023-06-30 00:00:00     1.166320e+12                     7.596419e+11   \n",
       "2  2023-05-31 00:00:00     1.112985e+12                     7.413980e+11   \n",
       "3  2023-04-30 00:00:00     1.095063e+12                     7.248563e+11   \n",
       "4  2023-03-31 00:00:00     1.083712e+12                     7.098920e+11   \n",
       "5  2023-02-28 00:00:00     1.084683e+12                     7.058291e+11   \n",
       "6  2023-01-31 00:00:00     1.087555e+12                     7.029266e+11   \n",
       "\n",
       "   sa_avg_balance_[general]_[priv]  sa_avg_balance_[general]_[vip]  \\\n",
       "0                     3.842425e+11                    3.443007e+10   \n",
       "1                     3.728167e+11                    3.386101e+10   \n",
       "2                     3.403776e+11                    3.120987e+10   \n",
       "3                     3.392324e+11                    3.097406e+10   \n",
       "4                     3.429391e+11                    3.088107e+10   \n",
       "5                     3.417648e+11                    3.708912e+10   \n",
       "6                     3.503515e+11                    3.427652e+10   \n",
       "\n",
       "   sa_weighted_rate_[general]_[mass]  sa_weighted_rate_[general]_[priv]  \\\n",
       "0                           5.578756                           5.085335   \n",
       "1                           5.497468                           5.075955   \n",
       "2                           5.396878                           5.044873   \n",
       "3                           5.305644                           5.001618   \n",
       "4                           5.130050                           4.904298   \n",
       "5                           5.076594                           4.871131   \n",
       "6                           5.028761                           4.852665   \n",
       "\n",
       "   sa_weighted_rate_[general]_[vip]  sa_weighted_rate_general     date  \\\n",
       "0                          4.810358                  4.810358  2023-07   \n",
       "1                          4.733183                  4.733183  2023-06   \n",
       "2                          4.737019                  4.737019  2023-05   \n",
       "3                          4.744042                  4.744042  2023-04   \n",
       "4                          4.714634                  4.714634  2023-03   \n",
       "5                          4.686045                  4.686045  2023-02   \n",
       "6                          4.687145                  4.687145  2023-01   \n",
       "\n",
       "   ftp_rate  ftp_month  margin_general   margin_mass   margin_priv  \\\n",
       "0      8.50   0.002255    2.863719e+09  1.871204e+09  9.108947e+08   \n",
       "1      8.26   0.002077    2.533464e+09  1.650084e+09  8.098277e+08   \n",
       "2      8.18   0.002063    2.461988e+09  1.640015e+09  7.529347e+08   \n",
       "3      8.18   0.002077    2.337946e+09  1.547560e+09  7.242572e+08   \n",
       "4      8.18   0.002094    2.417350e+09  1.583499e+09  7.649669e+08   \n",
       "5      8.18   0.002161    2.274744e+09  1.480230e+09  7.167325e+08   \n",
       "6      8.18   0.002164    2.524427e+09  1.631630e+09  8.132341e+08   \n",
       "\n",
       "     margin_vip  weighted_rate_calc  \n",
       "0  8.162076e+07            4.897288  \n",
       "1  7.355244e+07            4.886818  \n",
       "2  6.903803e+07            4.869371  \n",
       "3  6.612926e+07            4.851317  \n",
       "4  6.888395e+07            4.830554  \n",
       "5  7.778149e+07            4.829811  \n",
       "6  7.956249e+07            4.826586  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eff28dc0-b53d-4372-9873-f7d7a81ca816",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_fact['ftp_month'] = ((ftp_day)**(sa_fact['report_dt'].apply(lambda x: int(x[8:10])))-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "124616a5-42c1-4678-8a2e-656c0efc5338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.002299\n",
       "1    0.002049\n",
       "2    0.002102\n",
       "3    0.002049\n",
       "4    0.002134\n",
       "5    0.001990\n",
       "6    0.002206\n",
       "Name: ftp_month, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_fact['ftp_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "53effabb-4530-4105-9fc8-1fce06c82d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_fact['margin_general'] = sa_fact['ftp_month'] * sa_fact['balance_general']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c183bb41-92ce-4ea5-901e-0f6f322d35f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_fact['margin_mass'] = sa_fact['ftp_month'] * sa_fact['sa_avg_balance_[general]_[mass]']\n",
    "sa_fact['margin_priv'] = sa_fact['ftp_month'] * sa_fact['sa_avg_balance_[general]_[priv]']\n",
    "sa_fact['margin_vip'] = sa_fact['ftp_month'] * sa_fact['sa_avg_balance_[general]_[vip]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "058857b3-937f-42e2-a19e-94ca33743a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>5</th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>report_dt</th>\n",
       "      <td>2023-01-31 00:00:00</td>\n",
       "      <td>2023-02-28 00:00:00</td>\n",
       "      <td>2023-03-31 00:00:00</td>\n",
       "      <td>2023-04-30 00:00:00</td>\n",
       "      <td>2023-05-31 00:00:00</td>\n",
       "      <td>2023-06-30 00:00:00</td>\n",
       "      <td>2023-07-31 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance_general</th>\n",
       "      <td>1087554620912.959961</td>\n",
       "      <td>1084683033226.77002</td>\n",
       "      <td>1083712146191.5</td>\n",
       "      <td>1095062767847.319946</td>\n",
       "      <td>1112985392767.47998</td>\n",
       "      <td>1166319649864.360107</td>\n",
       "      <td>1208002117514.389893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>margin_general</th>\n",
       "      <td>2398727915.835428</td>\n",
       "      <td>2158021895.373902</td>\n",
       "      <td>2313133117.467195</td>\n",
       "      <td>2243619752.264263</td>\n",
       "      <td>2339749462.248781</td>\n",
       "      <td>2389614088.743225</td>\n",
       "      <td>2776744248.614958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>margin_priv</th>\n",
       "      <td>772740816.081146</td>\n",
       "      <td>679955333.835812</td>\n",
       "      <td>731987570.052635</td>\n",
       "      <td>695036448.356663</td>\n",
       "      <td>715551349.978634</td>\n",
       "      <td>763845586.779311</td>\n",
       "      <td>883229561.026883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>margin_vip</th>\n",
       "      <td>75600836.886325</td>\n",
       "      <td>73790350.247673</td>\n",
       "      <td>65914214.166457</td>\n",
       "      <td>63461222.183216</td>\n",
       "      <td>65610279.293459</td>\n",
       "      <td>69376125.962477</td>\n",
       "      <td>79141821.485811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>margin_mass</th>\n",
       "      <td>1550386262.867957</td>\n",
       "      <td>1404276211.290417</td>\n",
       "      <td>1515231333.248104</td>\n",
       "      <td>1485122081.724384</td>\n",
       "      <td>1558587832.976688</td>\n",
       "      <td>1556392376.001436</td>\n",
       "      <td>1814372866.102264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_rate_calc</th>\n",
       "      <td>4.826586</td>\n",
       "      <td>4.829811</td>\n",
       "      <td>4.830554</td>\n",
       "      <td>4.851317</td>\n",
       "      <td>4.869371</td>\n",
       "      <td>4.886818</td>\n",
       "      <td>4.897288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       6                    5  \\\n",
       "report_dt            2023-01-31 00:00:00  2023-02-28 00:00:00   \n",
       "balance_general     1087554620912.959961  1084683033226.77002   \n",
       "margin_general         2398727915.835428    2158021895.373902   \n",
       "margin_priv             772740816.081146     679955333.835812   \n",
       "margin_vip               75600836.886325      73790350.247673   \n",
       "margin_mass            1550386262.867957    1404276211.290417   \n",
       "weighted_rate_calc              4.826586             4.829811   \n",
       "\n",
       "                                      4                     3  \\\n",
       "report_dt           2023-03-31 00:00:00   2023-04-30 00:00:00   \n",
       "balance_general         1083712146191.5  1095062767847.319946   \n",
       "margin_general        2313133117.467195     2243619752.264263   \n",
       "margin_priv            731987570.052635      695036448.356663   \n",
       "margin_vip              65914214.166457       63461222.183216   \n",
       "margin_mass           1515231333.248104     1485122081.724384   \n",
       "weighted_rate_calc             4.830554              4.851317   \n",
       "\n",
       "                                      2                     1  \\\n",
       "report_dt           2023-05-31 00:00:00   2023-06-30 00:00:00   \n",
       "balance_general     1112985392767.47998  1166319649864.360107   \n",
       "margin_general        2339749462.248781     2389614088.743225   \n",
       "margin_priv            715551349.978634      763845586.779311   \n",
       "margin_vip              65610279.293459       69376125.962477   \n",
       "margin_mass           1558587832.976688     1556392376.001436   \n",
       "weighted_rate_calc             4.869371              4.886818   \n",
       "\n",
       "                                       0  \n",
       "report_dt            2023-07-31 00:00:00  \n",
       "balance_general     1208002117514.389893  \n",
       "margin_general         2776744248.614958  \n",
       "margin_priv             883229561.026883  \n",
       "margin_vip               79141821.485811  \n",
       "margin_mass            1814372866.102264  \n",
       "weighted_rate_calc              4.897288  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_fact[['report_dt', 'balance_general', 'margin_general', 'margin_priv', 'margin_vip', 'margin_mass', 'weighted_rate_calc']].sort_values(by='report_dt').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57f20bd5-6066-4023-bd6b-1923e49b967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_fact[['report_dt', 'balance_general', 'margin_general', 'margin_priv', 'margin_vip', 'margin_mass', 'sa_weighted_rate_general']].sort_values(by='report_dt').T.to_excel('sa_fact_res_v3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "946a2486-ff57-41cc-835e-c0f876b25604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_dt</th>\n",
       "      <th>balance_general</th>\n",
       "      <th>sa_avg_balance_[general]_[mass]</th>\n",
       "      <th>sa_avg_balance_[general]_[priv]</th>\n",
       "      <th>sa_avg_balance_[general]_[vip]</th>\n",
       "      <th>sa_weighted_rate_[general]_[mass]</th>\n",
       "      <th>sa_weighted_rate_[general]_[priv]</th>\n",
       "      <th>sa_weighted_rate_[general]_[vip]</th>\n",
       "      <th>sa_weighted_rate_general</th>\n",
       "      <th>date</th>\n",
       "      <th>ftp_rate</th>\n",
       "      <th>ftp_month</th>\n",
       "      <th>margin_general</th>\n",
       "      <th>margin_mass</th>\n",
       "      <th>margin_priv</th>\n",
       "      <th>margin_vip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-31 00:00:00</td>\n",
       "      <td>1.208002e+12</td>\n",
       "      <td>7.893295e+11</td>\n",
       "      <td>3.842425e+11</td>\n",
       "      <td>3.443007e+10</td>\n",
       "      <td>5.578756</td>\n",
       "      <td>5.085335</td>\n",
       "      <td>4.810358</td>\n",
       "      <td>4.810358</td>\n",
       "      <td>2023-07</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>2.863719e+09</td>\n",
       "      <td>1.871204e+09</td>\n",
       "      <td>9.108947e+08</td>\n",
       "      <td>8.162076e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-30 00:00:00</td>\n",
       "      <td>1.166320e+12</td>\n",
       "      <td>7.596419e+11</td>\n",
       "      <td>3.728167e+11</td>\n",
       "      <td>3.386101e+10</td>\n",
       "      <td>5.497468</td>\n",
       "      <td>5.075955</td>\n",
       "      <td>4.733183</td>\n",
       "      <td>4.733183</td>\n",
       "      <td>2023-06</td>\n",
       "      <td>8.26</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>2.533464e+09</td>\n",
       "      <td>1.650084e+09</td>\n",
       "      <td>8.098277e+08</td>\n",
       "      <td>7.355244e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-31 00:00:00</td>\n",
       "      <td>1.112985e+12</td>\n",
       "      <td>7.413980e+11</td>\n",
       "      <td>3.403776e+11</td>\n",
       "      <td>3.120987e+10</td>\n",
       "      <td>5.396878</td>\n",
       "      <td>5.044873</td>\n",
       "      <td>4.737019</td>\n",
       "      <td>4.737019</td>\n",
       "      <td>2023-05</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>2.461988e+09</td>\n",
       "      <td>1.640015e+09</td>\n",
       "      <td>7.529347e+08</td>\n",
       "      <td>6.903803e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-30 00:00:00</td>\n",
       "      <td>1.095063e+12</td>\n",
       "      <td>7.248563e+11</td>\n",
       "      <td>3.392324e+11</td>\n",
       "      <td>3.097406e+10</td>\n",
       "      <td>5.305644</td>\n",
       "      <td>5.001618</td>\n",
       "      <td>4.744042</td>\n",
       "      <td>4.744042</td>\n",
       "      <td>2023-04</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0.002135</td>\n",
       "      <td>2.337946e+09</td>\n",
       "      <td>1.547560e+09</td>\n",
       "      <td>7.242572e+08</td>\n",
       "      <td>6.612926e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-31 00:00:00</td>\n",
       "      <td>1.083712e+12</td>\n",
       "      <td>7.098920e+11</td>\n",
       "      <td>3.429391e+11</td>\n",
       "      <td>3.088107e+10</td>\n",
       "      <td>5.130050</td>\n",
       "      <td>4.904298</td>\n",
       "      <td>4.714634</td>\n",
       "      <td>4.714634</td>\n",
       "      <td>2023-03</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>2.417350e+09</td>\n",
       "      <td>1.583499e+09</td>\n",
       "      <td>7.649669e+08</td>\n",
       "      <td>6.888395e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-02-28 00:00:00</td>\n",
       "      <td>1.084683e+12</td>\n",
       "      <td>7.058291e+11</td>\n",
       "      <td>3.417648e+11</td>\n",
       "      <td>3.708912e+10</td>\n",
       "      <td>5.076594</td>\n",
       "      <td>4.871131</td>\n",
       "      <td>4.686045</td>\n",
       "      <td>4.686045</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>2.274744e+09</td>\n",
       "      <td>1.480230e+09</td>\n",
       "      <td>7.167325e+08</td>\n",
       "      <td>7.778149e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-31 00:00:00</td>\n",
       "      <td>1.087555e+12</td>\n",
       "      <td>7.029266e+11</td>\n",
       "      <td>3.503515e+11</td>\n",
       "      <td>3.427652e+10</td>\n",
       "      <td>5.028761</td>\n",
       "      <td>4.852665</td>\n",
       "      <td>4.687145</td>\n",
       "      <td>4.687145</td>\n",
       "      <td>2023-01</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>2.524427e+09</td>\n",
       "      <td>1.631630e+09</td>\n",
       "      <td>8.132341e+08</td>\n",
       "      <td>7.956249e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             report_dt  balance_general  sa_avg_balance_[general]_[mass]  \\\n",
       "0  2023-07-31 00:00:00     1.208002e+12                     7.893295e+11   \n",
       "1  2023-06-30 00:00:00     1.166320e+12                     7.596419e+11   \n",
       "2  2023-05-31 00:00:00     1.112985e+12                     7.413980e+11   \n",
       "3  2023-04-30 00:00:00     1.095063e+12                     7.248563e+11   \n",
       "4  2023-03-31 00:00:00     1.083712e+12                     7.098920e+11   \n",
       "5  2023-02-28 00:00:00     1.084683e+12                     7.058291e+11   \n",
       "6  2023-01-31 00:00:00     1.087555e+12                     7.029266e+11   \n",
       "\n",
       "   sa_avg_balance_[general]_[priv]  sa_avg_balance_[general]_[vip]  \\\n",
       "0                     3.842425e+11                    3.443007e+10   \n",
       "1                     3.728167e+11                    3.386101e+10   \n",
       "2                     3.403776e+11                    3.120987e+10   \n",
       "3                     3.392324e+11                    3.097406e+10   \n",
       "4                     3.429391e+11                    3.088107e+10   \n",
       "5                     3.417648e+11                    3.708912e+10   \n",
       "6                     3.503515e+11                    3.427652e+10   \n",
       "\n",
       "   sa_weighted_rate_[general]_[mass]  sa_weighted_rate_[general]_[priv]  \\\n",
       "0                           5.578756                           5.085335   \n",
       "1                           5.497468                           5.075955   \n",
       "2                           5.396878                           5.044873   \n",
       "3                           5.305644                           5.001618   \n",
       "4                           5.130050                           4.904298   \n",
       "5                           5.076594                           4.871131   \n",
       "6                           5.028761                           4.852665   \n",
       "\n",
       "   sa_weighted_rate_[general]_[vip]  sa_weighted_rate_general     date  \\\n",
       "0                          4.810358                  4.810358  2023-07   \n",
       "1                          4.733183                  4.733183  2023-06   \n",
       "2                          4.737019                  4.737019  2023-05   \n",
       "3                          4.744042                  4.744042  2023-04   \n",
       "4                          4.714634                  4.714634  2023-03   \n",
       "5                          4.686045                  4.686045  2023-02   \n",
       "6                          4.687145                  4.687145  2023-01   \n",
       "\n",
       "   ftp_rate  ftp_month  margin_general   margin_mass   margin_priv  \\\n",
       "0      8.50   0.002371    2.863719e+09  1.871204e+09  9.108947e+08   \n",
       "1      8.26   0.002172    2.533464e+09  1.650084e+09  8.098277e+08   \n",
       "2      8.18   0.002212    2.461988e+09  1.640015e+09  7.529347e+08   \n",
       "3      8.18   0.002135    2.337946e+09  1.547560e+09  7.242572e+08   \n",
       "4      8.18   0.002231    2.417350e+09  1.583499e+09  7.649669e+08   \n",
       "5      8.18   0.002097    2.274744e+09  1.480230e+09  7.167325e+08   \n",
       "6      8.18   0.002321    2.524427e+09  1.631630e+09  8.132341e+08   \n",
       "\n",
       "     margin_vip  \n",
       "0  8.162076e+07  \n",
       "1  7.355244e+07  \n",
       "2  6.903803e+07  \n",
       "3  6.612926e+07  \n",
       "4  6.888395e+07  \n",
       "5  7.778149e+07  \n",
       "6  7.956249e+07  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f70834b-8c7c-46e1-8fc5-7e17e6bc8263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6553d118-5a10-4c04-abdc-2e842b651f9f",
   "metadata": {},
   "source": [
    "Идея - трансфертная ставка идет на момент открытия. Попробовать рассчитать все это дело."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8243933b-701b-4c42-9bf7-ccae058a69f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'margin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/envs/hmelevskoi_env/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/envs/hmelevskoi_env/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/tmp/envs/hmelevskoi_env/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'margin'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12881/1198303776.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msa_fact\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'perc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msa_fact\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'margin'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msa_fact\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'balance_general'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m*\u001b[0m \u001b[0;36m365\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m30.3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/envs/hmelevskoi_env/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/envs/hmelevskoi_env/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'margin'"
     ]
    }
   ],
   "source": [
    "sa_fact['perc'] = sa_fact['margin'] / sa_fact['balance_general']  * 365 / 30.3 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ec355866-6b28-4ccf-a0b9-9f8d51efe999",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'perc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/envs/hmelevskoi_env/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/envs/hmelevskoi_env/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/tmp/envs/hmelevskoi_env/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'perc'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12881/2101407211.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msa_fact\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'perc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/envs/hmelevskoi_env/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/envs/hmelevskoi_env/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'perc'"
     ]
    }
   ],
   "source": [
    "sa_fact['perc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6beb09-ba78-41b0-b70b-6da1ad836aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59650fc5-611b-4e76-a0dc-41a427351a93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmelevskoi_env",
   "language": "python",
   "name": "hmelevskoi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
