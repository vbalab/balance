{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a64ec341-9ec8-4ba2-b1c9-a903ffee2b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn --force\n",
    "#!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "532f9d68-b0fc-4a7b-b166-b60981a74909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max.columns', 300)\n",
    "\n",
    "\n",
    "# from core.calculator.deposits import DepositsCalculationType\n",
    "# from core.calculator.deposits import DepositIterativeCalculator\n",
    "\n",
    "from core.definitions import *\n",
    "#from core.project_update import load_portfolio\n",
    "\n",
    "#from core.models import DepositModels\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9191a861-5357-4881-a639-2eacbd419624",
   "metadata": {},
   "source": [
    "## Корректируем таблицу по НС"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29e725f9-e187-4bda-8d4e-485aa861ad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для создания табличек\n",
    "\n",
    "from core.models.utils import run_spark_session\n",
    "spark = run_spark_session('create_table_tnd_v2')\n",
    "\n",
    "#spark = None #если без обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "291f602d-ed4d-4c1c-8d52-98319dfd1ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"\"\"\n",
    "\n",
    "with agg_t\n",
    "as\n",
    "(\n",
    "with df \n",
    "as\n",
    "\n",
    "(\n",
    "with dep \n",
    "as\n",
    "(\n",
    "SELECT * \n",
    "FROM prod_cdm.cd_deposit\n",
    "where deposit_type_cd='SA'\n",
    "and passive_acct_type_cd='CUR_ACCT'\n",
    "AND open_dt>'2010-01-01'\n",
    "AND deleted_flg='0'\n",
    "AND substring(account_num, 1, 5) in ('20309', '20310',\n",
    "        '30601', '30606', '30220', '30223', '30227', \n",
    "        '40803', '40810', '40813', '40817', '40820', '40823', '42301', '42309', '42601', '42609', '40901', \n",
    "        '40902', '40903', '40905', '40906', '40909', '40910', '40911', '40912', '40913', '40914', '47418')\n",
    "        \n",
    "and effective_from_dttm <= '2023-07-31'\n",
    "and effective_to_dttm >= '2023-07-01'\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "select \n",
    "report_date, \n",
    "agreement_rk, \n",
    "currency_iso_cd, \n",
    "open_dt, \n",
    "close_dt, \n",
    "product_bank_rk, \n",
    "product_rk, \n",
    "deposit_rate,\n",
    "interest_period_desc,\n",
    "account_num, \n",
    "currency_rk \n",
    "\n",
    "from dep\n",
    "left join\n",
    "(\n",
    "SELECT * \n",
    "FROM dadm_alm_sbx.t_enhanced_calendar\n",
    "where report_date >= '2023-07-01'\n",
    "and report_date <= '2023-07-31'\n",
    ") cal\n",
    "on (cal.report_date between dep.effective_from_dttm and dep.effective_to_dttm)\n",
    "and cal.report_date >= dep.open_dt \n",
    "and cal.report_date <= dep.close_dt \n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "select \n",
    "report_date, \n",
    "df.agreement_rk, \n",
    "currency_iso_cd, \n",
    "open_dt, \n",
    "close_dt, \n",
    "product_bank_rk, \n",
    "product_rk, \n",
    "deposit_rate,\n",
    "interest_period_desc,\n",
    "account_num, \n",
    "df.currency_rk,\n",
    "balance_rur_amt, \n",
    "balance_amt\n",
    "\n",
    "from df\n",
    "left join\n",
    "(select \n",
    "agreement_rk,\n",
    "currency_rk,\n",
    "balance_rur_amt,\n",
    "balance_amt,\n",
    "effective_from_dttm,\n",
    "effective_to_dttm\n",
    "from prod_cdm.fct_deposit_balance\n",
    "where balance_amt>1\n",
    "and deleted_flg='0') end_bal\n",
    "ON end_bal.agreement_rk = df.agreement_rk\n",
    "AND end_bal.currency_rk = df.currency_rk\n",
    "AND (df.report_date BETWEEN end_bal.effective_from_dttm AND end_bal.effective_to_dttm)\n",
    "and report_date >='2023-06-01'\n",
    "and report_date <='2023-08-01'\n",
    ")\n",
    "\n",
    "\n",
    "select sum(min_balance) as value from\n",
    "(\n",
    "select min(balance_rur_amt) as min_balance\n",
    "from agg_t\n",
    "group by agreement_rk) t1\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63013f93-60de-454d-9e36-46a0cf3e9b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:==============================================>       (190 + 33) / 223]23/10/25 17:20:38 ERROR cluster.YarnScheduler: Lost executor 9 on p0drp0-db5031xp.region.vtb.ru: Unable to create executor due to Address already in use: Service 'org.apache.spark.network.netty.NettyBlockTransferService' failed after 5 retries (starting from 62095)! Consider explicitly setting the appropriate port for the service 'org.apache.spark.network.netty.NettyBlockTransferService' (for example spark.ui.port for SparkUI) to an available port or increasing spark.port.maxRetries.\n",
      "23/10/25 17:20:38 ERROR cluster.YarnScheduler: Lost executor 12 on p0drp0-db5031xp.region.vtb.ru: Unable to create executor due to Address already in use: Service 'org.apache.spark.network.netty.NettyBlockTransferService' failed after 5 retries (starting from 62095)! Consider explicitly setting the appropriate port for the service 'org.apache.spark.network.netty.NettyBlockTransferService' (for example spark.ui.port for SparkUI) to an available port or increasing spark.port.maxRetries.\n",
      "23/10/25 17:20:38 ERROR cluster.YarnScheduler: Lost executor 18 on p0drp0-db5031xp.region.vtb.ru: Unable to create executor due to Address already in use: Service 'org.apache.spark.network.netty.NettyBlockTransferService' failed after 5 retries (starting from 62095)! Consider explicitly setting the appropriate port for the service 'org.apache.spark.network.netty.NettyBlockTransferService' (for example spark.ui.port for SparkUI) to an available port or increasing spark.port.maxRetries.\n",
      "23/10/25 17:20:38 ERROR cluster.YarnScheduler: Lost executor 13 on p0drp0-db5031xp.region.vtb.ru: Unable to create executor due to Address already in use: Service 'org.apache.spark.network.netty.NettyBlockTransferService' failed after 5 retries (starting from 62095)! Consider explicitly setting the appropriate port for the service 'org.apache.spark.network.netty.NettyBlockTransferService' (for example spark.ui.port for SparkUI) to an available port or increasing spark.port.maxRetries.\n",
      "[Stage 0:================================================>     (199 + 24) / 223]23/10/25 17:20:38 ERROR cluster.YarnScheduler: Lost executor 11 on p0drp0-db5031xp.region.vtb.ru: Unable to create executor due to Address already in use: Service 'org.apache.spark.network.netty.NettyBlockTransferService' failed after 5 retries (starting from 62095)! Consider explicitly setting the appropriate port for the service 'org.apache.spark.network.netty.NettyBlockTransferService' (for example spark.ui.port for SparkUI) to an available port or increasing spark.port.maxRetries.\n",
      "23/10/25 17:20:38 ERROR cluster.YarnScheduler: Lost executor 16 on p0drp0-db5031xp.region.vtb.ru: Unable to create executor due to Address already in use: Service 'org.apache.spark.network.netty.NettyBlockTransferService' failed after 5 retries (starting from 62095)! Consider explicitly setting the appropriate port for the service 'org.apache.spark.network.netty.NettyBlockTransferService' (for example spark.ui.port for SparkUI) to an available port or increasing spark.port.maxRetries.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.sql(query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1595362-5a86-4157-b612-4bd62ab38b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]23/10/25 18:08:36 ERROR cluster.YarnScheduler: Lost executor 45 on p0drp0-db5042xp.region.vtb.ru: Unable to create executor due to Address already in use: Service 'org.apache.spark.network.netty.NettyBlockTransferService' failed after 5 retries (starting from 62095)! Consider explicitly setting the appropriate port for the service 'org.apache.spark.network.netty.NettyBlockTransferService' (for example spark.ui.port for SparkUI) to an available port or increasing spark.port.maxRetries.\n",
      "23/10/25 18:08:36 ERROR cluster.YarnScheduler: Lost executor 35 on p0drp0-db5042xp.region.vtb.ru: Unable to create executor due to Address already in use: Service 'org.apache.spark.network.netty.NettyBlockTransferService' failed after 5 retries (starting from 62095)! Consider explicitly setting the appropriate port for the service 'org.apache.spark.network.netty.NettyBlockTransferService' (for example spark.ui.port for SparkUI) to an available port or increasing spark.port.maxRetries.\n",
      "23/10/25 18:08:36 ERROR cluster.YarnScheduler: Lost executor 33 on p0drp0-db5042xp.region.vtb.ru: Unable to create executor due to Address already in use: Service 'org.apache.spark.network.netty.NettyBlockTransferService' failed after 5 retries (starting from 62095)! Consider explicitly setting the appropriate port for the service 'org.apache.spark.network.netty.NettyBlockTransferService' (for example spark.ui.port for SparkUI) to an available port or increasing spark.port.maxRetries.\n",
      "23/10/25 18:08:36 ERROR cluster.YarnScheduler: Lost executor 36 on p0drp0-db5042xp.region.vtb.ru: Unable to create executor due to Address already in use: Service 'org.apache.spark.network.netty.NettyBlockTransferService' failed after 5 retries (starting from 62095)! Consider explicitly setting the appropriate port for the service 'org.apache.spark.network.netty.NettyBlockTransferService' (for example spark.ui.port for SparkUI) to an available port or increasing spark.port.maxRetries.\n",
      "23/10/25 18:08:36 ERROR cluster.YarnScheduler: Lost executor 43 on p0drp0-db5042xp.region.vtb.ru: Unable to create executor due to Address already in use: Service 'org.apache.spark.network.netty.NettyBlockTransferService' failed after 5 retries (starting from 62095)! Consider explicitly setting the appropriate port for the service 'org.apache.spark.network.netty.NettyBlockTransferService' (for example spark.ui.port for SparkUI) to an available port or increasing spark.port.maxRetries.\n",
      "23/10/25 18:08:37 ERROR cluster.YarnScheduler: Lost executor 31 on p0drp0-db5042xp.region.vtb.ru: Unable to create executor due to Address already in use: Service 'org.apache.spark.network.netty.NettyBlockTransferService' failed after 5 retries (starting from 62095)! Consider explicitly setting the appropriate port for the service 'org.apache.spark.network.netty.NettyBlockTransferService' (for example spark.ui.port for SparkUI) to an available port or increasing spark.port.maxRetries.\n",
      "23/10/25 18:08:37 ERROR cluster.YarnScheduler: Lost executor 32 on p0drp0-db5042xp.region.vtb.ru: Unable to create executor due to Address already in use: Service 'org.apache.spark.network.netty.NettyBlockTransferService' failed after 5 retries (starting from 62095)! Consider explicitly setting the appropriate port for the service 'org.apache.spark.network.netty.NettyBlockTransferService' (for example spark.ui.port for SparkUI) to an available port or increasing spark.port.maxRetries.\n",
      "23/10/25 18:08:37 ERROR cluster.YarnScheduler: Lost executor 34 on p0drp0-db5042xp.region.vtb.ru: Unable to create executor due to Address already in use: Service 'org.apache.spark.network.netty.NettyBlockTransferService' failed after 5 retries (starting from 62095)! Consider explicitly setting the appropriate port for the service 'org.apache.spark.network.netty.NettyBlockTransferService' (for example spark.ui.port for SparkUI) to an available port or increasing spark.port.maxRetries.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.mode('overwrite').saveAsTable('dadm_alm_sbx.tmp_jun_sa_daily_value2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b3b072b-1b13-41de-b35b-aec2135105f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = spark.table('dadm_alm_sbx.tmp_jun_sa_daily_value2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6310142d-dc5a-48de-8002-3206ed09fb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|              value|\n",
      "+-------------------+\n",
      "|1162128190575.78000|\n",
      "+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tmp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9039b62-762f-44e9-9fd2-133d588d9b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "1162128190575"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa0a7d3-af76-436a-a8e3-199ddb8d2cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "1066878751900.35000/ 10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d75ccd-59ea-4e18-8708-ab55e7f25ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03afbdb4-4a01-4c24-8172-b8d3dec2a3d0",
   "metadata": {},
   "source": [
    "## Калькулятор маржи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72be3b50-06d0-4ee2-b9e3-515a4233b5b4",
   "metadata": {},
   "source": [
    "Внутренняя стоимость средств на накопительных счетах (ВССНС) ФЛ в рублях  \n",
    "устанавливается в виде фиксированной ставки как сумма значения Ключевой  \n",
    "ставки Банка России и надбавки, равной среднекалендарному значению  \n",
    "трансфертной ставки в рублях на базе КС на срок 1 год за предшествующие дате  \n",
    "расчета 1095 дней (с учетом выходных и праздничных дней).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695942d0-c97b-40b8-8e28-21edd7b1bfd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ab01d-2458-40f5-8efe-4de781980db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4ee440-5306-442e-919d-5b1c94805dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59650fc5-611b-4e76-a0dc-41a427351a93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADH-USERS Python 3 + PySpark 2",
   "language": "python",
   "name": "python3-pyspark2-adh-users"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
